{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e1be4e5-92b0-498e-a2af-096fb4ad39a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from torch.utils.data import DataLoader, Dataset, random_split\n",
    "\n",
    "import albumentations as A\n",
    "from albumentations.pytorch.transforms import ToTensorV2\n",
    "\n",
    "import cv2\n",
    "import torchvision\n",
    "from torchvision import transforms as T\n",
    "from torchvision import datasets, models\n",
    "from torchvision.datasets import ImageFolder\n",
    "\n",
    "from torchmetrics.classification import MulticlassJaccardIndex\n",
    "\n",
    "import sklearn\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "\n",
    "import segmentation_models_pytorch as smp\n",
    "\n",
    "import wandb\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e98dbb34-0cba-4b69-aec3-5d98f0d508aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set seed for reproducibility\n",
    "LUCKY_SEED = 42\n",
    "torch.manual_seed(LUCKY_SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(LUCKY_SEED)\n",
    "np.random.seed(LUCKY_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bc2dc09-6cb7-4b1f-a40a-ca40bbb6b123",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = smp.Unet(\n",
    "    encoder_name=\"efficientnet-b1\",        \n",
    "    encoder_weights=\"imagenet\",                  \n",
    "    classes=23\n",
    ")\n",
    "model.load_state_dict(torch.load('weights.pt')) # load weights from trained model\n",
    "model.to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb99c48d-5fc9-42e7-a4d7-0d424b92645e",
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms_test = A.Compose([\n",
    "    A.Resize(352, 512),\n",
    "    A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ToTensorV2()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "752ce4ce-fd51-4dd0-9bf1-c5c2c7d9de7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomTestDataset(Dataset):\n",
    "    def __init__(self, img_path, csv, transform = None):\n",
    "        self.img_path = img_path\n",
    "        self.csv = csv\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.csv)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(self.img_path, self.csv.iloc[idx, 0]) + '.jpg'\n",
    "        img = cv2.imread(img_path)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        img_orig = img # orig image w/o normalization to display later on graphs\n",
    "    \n",
    "        if self.transform is not None:\n",
    "            aug = self.transform(image = img)\n",
    "            img = aug[\"image\"]\n",
    "            \n",
    "        img = img.float()\n",
    "        \n",
    "        return img, img_orig "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d18a41ac-17f5-4f79-9fb7-3d023ad3f049",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = \"specify image folder path here\"\n",
    "csv = pd.read_csv(\"specify .csv with image names path here\")\n",
    "test_dataset = CustomTestDataset(img_path, csv, transform = transforms_test)\n",
    "testloader = DataLoader(test_dataset, batch_size = 8, shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dc2a429-0994-4cc4-a4a3-c44600d7bcb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# display random image result\n",
    "img, img_orig = test_dataset[0] \n",
    "img = img.to(device)\n",
    "img = img.view(-1, 3, 352, 512) # need to include batch size\n",
    "pred = model(img)\n",
    "mask = torch.argmax(pred, dim = 1)\n",
    "\n",
    "figure, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize = (30, 10))\n",
    "\n",
    "ax1.imshow(img_orig.permute(1,2,0)) # change image shape from CxHxW to HxWxC\n",
    "ax1.set_title(\"original image\")\n",
    "\n",
    "ax2.imshow(mask.cpu().squeeze()) #squeeze чтобы убрать dim по батчам\n",
    "ax2.set_title(\"original mask\")\n",
    "\n",
    "ax3.imshow(masked.cpu().squeeze())\n",
    "ax3.set_title(\"pred mask, mIoU score = \" + str(score.item()))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
